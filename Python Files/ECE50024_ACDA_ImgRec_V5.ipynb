{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:23:26.481358Z",
     "end_time": "2023-05-05T16:23:26.484375Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Necessary Libraries\n",
    "import tensorflow as tf\n",
    "from keras.layers import Layer\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define Adaptive Convolutional Layer\n",
    "\n",
    "# Initialize expected input for TF model\n",
    "inputs = tf.keras.Input(shape=(150, 150, 3))\n",
    "\n",
    "# The following class accepts an initial filter and kernel size and conducts the adaptive convolution operation on the input\n",
    "class AdaptiveConvLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size):\n",
    "        super(AdaptiveConvLayer, self).__init__()\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv_weights = self.add_weight(shape=(self.kernel_size, self.kernel_size, input_shape[-1], self.filters),\n",
    "                                            initializer='random_normal',\n",
    "                                            trainable=True)\n",
    "        super(AdaptiveConvLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        output = tf.nn.conv2d(inputs, self.conv_weights, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        return output\n",
    "\n",
    "    # Generate Kernel Weights for Iteration and Return to Model\n",
    "    def get_kernel_weights(self):\n",
    "        return self.conv_weights\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:23:01.381775Z",
     "end_time": "2023-05-05T16:23:01.397680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Define the CustomModel class\n",
    "\n",
    "# Global function for running the ACDA algorithm. The third function, 'get_kernel_weights' returns the kernel weights over each epoch.\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.adaptive_conv = AdaptiveConvLayer(filters=3, kernel_size=3)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense = tf.keras.layers.Dense(6, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.adaptive_conv(inputs)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "\n",
    "    def get_kernel_weights(self):\n",
    "        return self.adaptive_conv.get_kernel_weights()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:23:02.111676Z",
     "end_time": "2023-05-05T16:23:02.121781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Define a custom callback to save kernel weights after each epoch\n",
    "\n",
    "# The following function saves the returned kernel weights and saves them to a csv file for analysis.\n",
    "class SaveKernelWeightsCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, csv_writer):\n",
    "        super(SaveKernelWeightsCallback, self).__init__()\n",
    "        self.model = model\n",
    "        self.csv_writer = csv_writer\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Get the kernel weights of the AdaptiveConvLayer\n",
    "        kernel_weights = self.model.get_kernel_weights()\n",
    "\n",
    "        # Flatten the kernel weights for writing to csv\n",
    "        flattened_weights = kernel_weights.numpy().flatten()\n",
    "\n",
    "        # Prepare the row to write to csv\n",
    "        row = [epoch] + list(flattened_weights)\n",
    "\n",
    "        # Write the row to the csv file\n",
    "        self.csv_writer.writerow(row)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:23:02.861384Z",
     "end_time": "2023-05-05T16:23:02.871631Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Create an instance of the custom model\n",
    "model = CustomModel()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:23:03.682400Z",
     "end_time": "2023-05-05T16:23:03.714218Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14034 files belonging to 6 classes.\n",
      "Using 11228 files for training.\n",
      "Epoch 1/10\n",
      "351/351 [==============================] - 15s 41ms/step - loss: 35.2231 - accuracy: 0.3988\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 9s 27ms/step - loss: 8.0680 - accuracy: 0.7101\n",
      "Epoch 3/10\n",
      "351/351 [==============================] - 9s 25ms/step - loss: 2.6433 - accuracy: 0.8362\n",
      "Epoch 4/10\n",
      "351/351 [==============================] - 10s 27ms/step - loss: 2.2094 - accuracy: 0.8592\n",
      "Epoch 5/10\n",
      "351/351 [==============================] - 10s 28ms/step - loss: 28.8464 - accuracy: 0.7279\n",
      "Epoch 6/10\n",
      "351/351 [==============================] - 11s 32ms/step - loss: 3.0547 - accuracy: 0.8838\n",
      "Epoch 7/10\n",
      "351/351 [==============================] - 9s 25ms/step - loss: 0.7220 - accuracy: 0.9575\n",
      "Epoch 8/10\n",
      "351/351 [==============================] - 8s 22ms/step - loss: 0.4229 - accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "351/351 [==============================] - 10s 29ms/step - loss: 0.3742 - accuracy: 0.9814\n",
      "Epoch 10/10\n",
      "351/351 [==============================] - 9s 26ms/step - loss: 0.4251 - accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "# Initialize the csv file and writer\n",
    "csv_file = open('weights.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "\n",
    "# Write the header row in the csv file\n",
    "header = ['Epoch'] + [f'Weight_{i+1}' for i in range(model.adaptive_conv.kernel_size**2)]\n",
    "csv_writer.writerow(header)\n",
    "\n",
    "# Create the callback to save kernel weights after each epoch\n",
    "save_weights_callback = SaveKernelWeightsCallback(model, csv_writer)\n",
    "\n",
    "# Initialize necessary parameters\n",
    "train_data_dir = \"seg_train\" # Training Image folder\n",
    "batch_size = 32\n",
    "image_size = (150, 150)\n",
    "\n",
    "# Create the training dataset variable\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    batch_size=batch_size,\n",
    "    image_size=image_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "# Compile ACDA Model\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Train the model with the callback to acquire weights\n",
    "model.fit(train_dataset, epochs=10, callbacks=[save_weights_callback], batch_size=32)\n",
    "\n",
    "# Close the csv file\n",
    "# Close the csv file\n",
    "csv_file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:23:59.030913Z",
     "end_time": "2023-05-05T16:25:39.895008Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " adaptive_conv_layer (Adapti  multiple                 81        \n",
      " veConvLayer)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  405006    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 405,087\n",
      "Trainable params: 405,087\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Output Model Summary\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:29:51.547502Z",
     "end_time": "2023-05-05T16:29:51.563376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Save the model's generated weights\n",
    "model.save_weights('TF_Models/ECE50024_ACDA_TF_V4.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-05T16:29:54.602517Z",
     "end_time": "2023-05-05T16:29:54.648146Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
